# -*- coding: utf-8 -*-
"""day2_Lab_Classification_Advanced.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MwE4VFSfZKcPQkDE8uT4886i3beEba2v

# Classification

> In this notebook we will cover the preprocessing of a tabular data and will use following algorithms:

> 1. Logistic Regression
> 2. Support Vector Machine
> 3. Decision Tree Classifier
> 4. Random Forest Classifier
> 5. XGBoost Classifier
> 6. CatBoost Classifier

---

# Data
https://www.kaggle.com/datasets/nikhil7280/weather-type-classification/data
> This dataset is generated to mimic weather data for classification tasks. It includes various weather-related features and categorizes the weather into four types: Rainy, Sunny, Cloudy, and Snowy.
>
> This is a Multiclass-Classification problem.
>
> The data contains the following columns:

> * Temperature (numeric): The temperature in degrees Celsius, ranging from extreme cold to extreme heat.
> * Humidity (numeric): The humidity percentage, including values above 100% to introduce outliers.
> * Wind Speed (numeric): The wind speed in kilometers per hour, with a range including unrealistically high values.
> * Precipitation (%) (numeric): The precipitation percentage, including outlier values.
> * Cloud Cover (categorical): The cloud cover description.
> * Atmospheric Pressure (numeric): The atmospheric pressure in hPa, covering a wide range.
> * UV Index (numeric): The UV index, indicating the strength of ultraviolet radiation.
> * Season (categorical): The season during which the data was recorded.
> * Visibility (km) (numeric): The visibility in kilometers, including very low or very high values.
> * Location (categorical): The type of location where the data was recorded.
> * Weather Type (categorical): The target variable for classification, indicating the weather type.

#  Import Libraries
"""

from IPython.display import clear_output

!pip install dask[dataframe] catboost

clear_output()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub
import os

# %matplotlib inline

"""##  Read the Data"""

# Download latest version
path = kagglehub.dataset_download("nikhil7280/weather-type-classification")

print("Path to dataset files:", path)

csv_path = os.path.join(path, "weather_classification_data.csv")

df = pd.read_csv(csv_path)
df.head()

df.info()

"""# ðŸ“Š Exploratory Data Analysis (EDA)

#### Points you should answer with your EDA:

##### 1- Is the target imbalanced? If yes, you should use appropriate metric (Precision, Recall, F1, AUC,...), and use appropriate split (StraitifiedKFold, For more info: [link](https://medium.com/@juanc.olamendy/a-comprehensive-guide-to-stratified-k-fold-cross-validation-for-unbalanced-data-014691060f17) )
##### 2- Do we have missing values? If yes, you should handle them (Note: Gradient Boosting algorithms can work even if there are missing values).
##### 3- Do we have catogerical columns? If yes, you should encode them.
##### 4- Do we have duplicates samples? If yes, you should drop them.
##### 5- Do I have different scales in the data? If yes, you should standardize them (Note: This is important for all the algorithms except tree models.)
"""

# 1. Is the target imbalanced?
print("Target Distribution:")
distribution = df["Weather Type"].value_counts()
print(distribution)

print("\nTarget Distribution Normalized:")
distribution_normalized = df["Weather Type"].value_counts(normalize=True)
print(distribution_normalized)

sns.countplot(x=df["Weather Type"])
plt.title("Target Distribution")
plt.show()

"""##### No imbalance. So we can use Accuracy as a metric (we can show the others as well), and use KFold for splitting later."""

# 2. Do we have missing values?
display(df.isnull().sum())

assert df.isnull().sum().all() == 0

"""No missing values"""

# 3. Do we have categorical columns?
categorical_cols = df.select_dtypes(include=["object"]).columns
print("Categorical Columns:", list(categorical_cols))

"""##### We have several categorical columns. Let's encode them using Label Encoder."""

from sklearn.preprocessing import LabelEncoder

categorical_cols = df.select_dtypes(include=["object"]).columns
le = LabelEncoder()

for col in categorical_cols:
    print(f"Encoding column: {col}")
    df[col] = le.fit_transform(df[col])

df

# 4. Do we have duplicate samples?
duplicates = df.duplicated().sum()
print(f"Number of Duplicate Samples: {duplicates}")
if duplicates > 0:
    print("Dropping Duplicates...")
    df.drop_duplicates(inplace=True)
    print("Duplicates Dropped.")
else:
    print("No Duplicate Samples Found.")

"""##### If we have duplicates, we could use df = df.drop_duplicates().reset_index(drop=True) to drop them"""

# 5. Do we have different scales in the data?
df.describe()

"""##### Yes, we have different scales, and we will use several algorithms that needs scaling.
##### Let's use MinMaxScaler to scale the data.
"""

from sklearn.preprocessing import MinMaxScaler
features = df.columns.drop("Weather Type")  ### DON'T SCALE THE TARGET
print("Features:", list(features))

scaler = MinMaxScaler()
df[features] = scaler.fit_transform(df[features])
df

"""#  Training our Classification Models

> We will need to first split up our data into an X array that contains the features to train on, and a y array with the target variable, in this case, the Weather Type column.
"""

X = df.drop("Weather Type",axis=1)
y = df['Weather Type']

"""> We will use KFold to evaluate our models"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Define classification models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Support Vector Machine": SVC(kernel='rbf'),
    "Decision Tree Classifier": DecisionTreeClassifier(max_depth=5),
    "Random Forest Classifier": RandomForestClassifier(n_estimators=100),
    "XGBoost Classifier": XGBClassifier(verbosity=0),
    "CatBoost Classifier": CatBoostClassifier(verbose=0)
}


for model_name, model in models.items():
    scores_accuracy = []
    scores_precision = []
    scores_recall = []
    scores_f1 = []

    # Stratified 5-Fold Cross-Validation
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    for train_index, test_index in skf.split(X, y):
        # Split data into training and testing sets
        X_Train, X_Test = X.loc[train_index, :], X.loc[test_index, :]
        y_Train, y_Test = y.iloc[train_index], y.iloc[test_index]
        # Train the model
        model.fit(X_Train, y_Train)
        # Predict on the test set
        y_pred = model.predict(X_Test)

        # Calculate metrics
        scores_accuracy.append(accuracy_score(y_Test, y_pred))
        scores_precision.append(precision_score(y_Test, y_pred, average='weighted'))
        scores_recall.append(recall_score(y_Test, y_pred, average='weighted'))
        scores_f1.append(f1_score(y_Test, y_pred, average='weighted'))

    # Print the results
    print(f"{model_name} Accuracy: {np.mean(scores_accuracy):.4f}")
    print(f"{model_name} Precision: {np.mean(scores_precision):.4f}")
    print(f"{model_name} Recall: {np.mean(scores_recall):.4f}")
    print(f"{model_name} F1-Score: {np.mean(scores_f1):.4f}")
    print("\n")

"""> * Is 91% Accuracy Good? We Need a Baseline.
>
> * What is the Simplest Baseline? Always predicting the majority class (e.g., if 80% of data is one class, accuracy = 80%).
>
> * If Our Model Beats the Baseline, Itâ€™s Good.

"""

from sklearn.metrics import classification_report

# Set random seed
np.random.seed(42)

# Calculate the majority class baseline
baseline_pred = np.random.randint(0, 4, size=len(y))

# Evaluate the baseline
print(classification_report(y, baseline_pred, target_names=['Clear', 'Cloudy', 'Rain', 'Snow']))

"""> * Our models are significanlty better than the baselines.
>
> * Let's Check what are the important features.
"""

# Retrieve Logistic Regression coefficients and sort by absolute importance
logistic_importance = list(zip(X.columns, models["Logistic Regression"].coef_[0]))
sorted_logistic_importance = sorted(logistic_importance, key=lambda x: abs(x[1]), reverse=True)

# Extract sorted features and their coefficients
features, coefficients = zip(*sorted_logistic_importance)

# Plot feature importances
plt.figure(figsize=(10, 6))
plt.barh(features, np.abs(coefficients), color='darkblue')
plt.xlabel('Coefficient Value')
plt.ylabel('Features')
plt.title('Logistic Regression Feature Importance')
plt.gca().invert_yaxis()  # Invert y-axis to show the most important features at the top
plt.show()

# Retrieve XGBoost feature importances
xgb_importances = models["XGBoost Classifier"].feature_importances_

# Create a sorted list of feature importance
sorted_idx = np.argsort(xgb_importances)[::-1]
sorted_features = X.columns[sorted_idx]
sorted_importances = xgb_importances[sorted_idx]

# Plot feature importances
plt.figure(figsize=(10, 6))
plt.barh(sorted_features, sorted_importances, color='brown')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.title('XGBoost Feature Importance')
plt.gca().invert_yaxis()  # Invert y-axis to show the most important features at the top
plt.show()

# Retrieve CatBoost feature importances and sort them
catboost_model = models["CatBoost Classifier"]
catboost_importance = list(zip(X.columns, catboost_model.feature_importances_))
sorted_catboost_importance = sorted(catboost_importance, key=lambda x: x[1], reverse=True)

# Extract features and their importances
features, importances = zip(*sorted_catboost_importance)

# Plot feature importances
plt.figure(figsize=(10, 6))
plt.barh(features, importances, color='orange')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.title('CatBoost Feature Importance')
plt.gca().invert_yaxis()  # Invert y-axis to show the most important features at the top
plt.show()

"""## Final Notes:
> * Notice how different models depend on different features. "Cloud Cover" is the top feature for XGBoost while it is less important for the other models. (Do you think we could combine these models somehow to achieve even better results? Hint: Consider using something other than model.predict().)

> * Gradient Boosting algorithms (e.g., XGBoost, LightGBM, CatBoost) often outperform other algorithms in tabular data.


> * Want to improve performance even further? Try to do feature engineering and Hyperparameters tuning, and keep evaluating your work against the CV.

# Created by:
[Mohamed Eltayeb](https://www.kaggle.com/mohammad2012191)
"""