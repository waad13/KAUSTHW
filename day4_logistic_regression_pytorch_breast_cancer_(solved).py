# -*- coding: utf-8 -*-
"""day4_Logistic_Regression_Pytorch_Breast_Cancer (Solved).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R_AJMLPOmme0aBQdnhIhmGhQY6efsHNG
"""

from IPython.display import clear_output

# Commented out IPython magic to ensure Python compatibility.
# Download the required libraries (needed when running outside colab where the environment doesn't come pre-loaded with libraries)

# %pip install torch
# %pip install matplotlib
# %pip install scikit-learn

clear_output()

import torch
import torch.nn as nn
from torch.optim import SGD

import matplotlib.pyplot as plt

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

"""#Contents:

1. Implementation of Logistic Regression using Pytorch to make a classifier for Breat Cancer Dataset

You need to know:

1. **pytorch** (for impelementation)
2. a little bit of **matplotlib** (for visualization)

## Loading Data
"""

data = load_breast_cancer()

print(data.DESCR)  # description of dataset

print('feature_names:', data.feature_names)
print('-'*20)
print('target_names:', data.target_names)

# Load the Breast Cancer dataset

X = data.data
y = data.target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train = torch.tensor(X_train, dtype=torch.float32)
X_test  = torch.tensor(X_test, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32)
y_test  = torch.tensor(y_test, dtype=torch.float32)

print(f'{X.shape=}')
print(f'{y.shape=}')
print('-'*10)
print(f'{X_train.shape=}')
print(f'{X_test.shape=}')
print('-'*10)
print(f'{y_train.shape=}')
print(f'{y_test.shape=}')

# Torch module based model for logistic_regression
class LogisticRegression(nn.Module):
  def __init__(self, input_dim):
    super(LogisticRegression, self).__init__()
    self.linear_weights = nn.Linear(input_dim, 1)

  def forward(self, x):
    y = self.linear_weights(x)
    z = torch.sigmoid(y)  # a sigmoid over a linear layer output
    return z

input_dim = X_train.shape[1]
model = LogisticRegression(input_dim)

# Define loss function and optimizer
criterion = nn.BCELoss()  # Binary Cross Entropy Loss (binary because 2 classes). Cross entropy function in torch is multi-class
optimizer = SGD(model.parameters(), lr=0.01)

num_epochs = 1000
lr = 1e-2

"""## Training the model"""

train_losses = []

for epoch in range(num_epochs):
  # Forward pass
  outputs = model(X_train)
  loss = criterion(outputs, y_train.unsqueeze(dim=-1))

  # Backward pass and optimization
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()

  train_losses.append(loss.item())

  if (epoch + 1) % 100 == 0:
    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

plt.plot(train_losses)

plt.xlabel('epoch')
plt.ylabel('loss (BCE)')

plt.show()

model.eval()
with torch.no_grad():

  y_pred = model(X_test)
  y_pred = (y_pred > 0.5).float()  # Convert probabilities to binary predictions (0 or 1)

  correct = (y_pred == y_test.view(-1, 1)).sum().item()
  accuracy = correct / y_test.size(0)

  print(f'Accuracy on test set: {100 * accuracy:.2f}%')

